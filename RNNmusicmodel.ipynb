{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87ebf663",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 1276\n",
      "C:\\Users\\oubra\\OneDrive\\Documents\\maestro-v3.0.0-midi\\maestro-v3.0.0\\2004\\MIDI-Unprocessed_SMF_02_R1_2004_01-05_ORIG_MID--AUDIO_02_R1_2004_06_Track06_wav.midi\n",
      "Number of instruments: 1\n",
      "Instrument name: Acoustic Grand Piano\n",
      "0: pitch=31, note_name=G1, duration=0.0656\n",
      "1: pitch=43, note_name=G2, duration=0.0792\n",
      "2: pitch=44, note_name=G#2, duration=0.0740\n",
      "3: pitch=32, note_name=G#1, duration=0.0729\n",
      "4: pitch=34, note_name=A#1, duration=0.0708\n",
      "5: pitch=46, note_name=A#2, duration=0.0948\n",
      "6: pitch=48, note_name=C3, duration=0.6260\n",
      "7: pitch=36, note_name=C2, duration=0.6542\n",
      "8: pitch=53, note_name=F3, duration=1.7667\n",
      "9: pitch=56, note_name=G#3, duration=1.7688\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pitch</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>step</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>1.032292</td>\n",
       "      <td>1.111458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>1.040625</td>\n",
       "      <td>1.106250</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.065625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>1.142708</td>\n",
       "      <td>1.216667</td>\n",
       "      <td>0.102083</td>\n",
       "      <td>0.073958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>1.144792</td>\n",
       "      <td>1.217708</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.072917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pitch     start       end      step  duration\n",
       "0     43  1.032292  1.111458  0.000000  0.079167\n",
       "1     31  1.040625  1.106250  0.008333  0.065625\n",
       "2     44  1.142708  1.216667  0.102083  0.073958\n",
       "3     32  1.144792  1.217708  0.002083  0.072917"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "import datetime\n",
    "# import fluidsynth\n",
    "import glob\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import pretty_midi\n",
    "import seaborn as sns\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Dict, List, Optional, Sequence, Tuple\n",
    "\n",
    "#pytorch stuff\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset  # Importing data utilities from PyTorch.\n",
    "import torch.nn as nn  # Base class for all neural network modules.\n",
    "import torch.nn.functional as F  # Contains functions that don't have any parameters.\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else cpu)\n",
    "data_dir = pathlib.Path('C:/Users/oubra/OneDrive/Documents/maestro-v3.0.0-midi/maestro-v3.0.0')\n",
    "filenames = glob.glob(str(data_dir/'**/*.mid*'))\n",
    "print('Number of files:', len(filenames))\n",
    "sample_file = filenames[1]\n",
    "print(sample_file)\n",
    "\n",
    "pm = pretty_midi.PrettyMIDI(sample_file)\n",
    "\n",
    "print('Number of instruments:', len(pm.instruments))\n",
    "instrument = pm.instruments[0]\n",
    "instrument_name = pretty_midi.program_to_instrument_name(instrument.program)\n",
    "print('Instrument name:', instrument_name)\n",
    "\n",
    "#Print some information about the first 10 notes in the instrument track.\n",
    "for i, note in enumerate(instrument.notes[:10]):\n",
    "  note_name = pretty_midi.note_number_to_name(note.pitch)\n",
    "  duration = note.end - note.start\n",
    "  print(f'{i}: pitch={note.pitch}, note_name={note_name},'\n",
    "        f' duration={duration:.4f}')\n",
    "\n",
    "# Define a function to convert MIDI data to notes in a pandas DataFrame.\n",
    "def midi_to_notes(midi_file: str) -> pd.DataFrame:\n",
    "  pm = pretty_midi.PrettyMIDI(midi_file)\n",
    "  instrument = pm.instruments[0]\n",
    "  notes = collections.defaultdict(list)\n",
    "\n",
    "  # Sort the notes by start time\n",
    "  sorted_notes = sorted(instrument.notes, key=lambda note: note.start)\n",
    "  prev_start = sorted_notes[0].start\n",
    "\n",
    "  for note in sorted_notes:\n",
    "    start = note.start\n",
    "    end = note.end\n",
    "    notes['pitch'].append(note.pitch)\n",
    "    notes['start'].append(start)\n",
    "    notes['end'].append(end)\n",
    "    notes['step'].append(start - prev_start)\n",
    "    notes['duration'].append(end - start)\n",
    "    prev_start = start\n",
    "\n",
    "    # Return the notes as a pandas DataFrame\n",
    "  return pd.DataFrame({name: np.array(value) for name, value in notes.items()})\n",
    "\n",
    "raw_notes = midi_to_notes(sample_file)\n",
    "raw_notes.head(4)\n",
    "# def display_audio(pm: pretty_midi.PrettyMIDI, seconds=30):\n",
    "#   waveform = pm.fluidsynth(fs=_SAMPLING_RATE)\n",
    "#   # Take a sample of the generated waveform to mitigate kernel resets\n",
    "#   waveform_short = waveform[:seconds*_SAMPLING_RATE]\n",
    "#   return display.Audio(waveform_short, rate=_SAMPLING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42dd9ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of MIDI files to be processed.\n",
    "num_files = 10\n",
    "\n",
    "# Create an empty list to store the notes DataFrames.\n",
    "all_notes = []\n",
    "\n",
    "# Iterate over the first num_files MIDI files in the filenames list.\n",
    "for f in filenames[:num_files]:\n",
    "  # Convert each MIDI file to a DataFrame of notes using the midi_to_notes function and append the DataFrame to the list.\n",
    "  notes = midi_to_notes(f)\n",
    "  all_notes.append(notes)\n",
    "\n",
    "# Concatenate all the notes DataFrames into one DataFrame.\n",
    "all_notes = pd.concat(all_notes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f6ed8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68137, 5)\n",
      "Number of notes parsed: 68137\n"
     ]
    }
   ],
   "source": [
    "# Get the total number of notes in the DataFrame.\n",
    "n_notes = len(all_notes)\n",
    "print(all_notes.shape)\n",
    "print('Number of notes parsed:', n_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aa641e8-0eed-4154-99a0-b4d39bff7d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/1065], Loss: 534503.125\n",
      "Epoch [1/5], Step [200/1065], Loss: 275770.5625\n",
      "Epoch [1/5], Step [300/1065], Loss: 281464.625\n",
      "Epoch [1/5], Step [400/1065], Loss: 243661.46875\n",
      "Epoch [1/5], Step [500/1065], Loss: 278209.0\n",
      "Epoch [1/5], Step [600/1065], Loss: 227195.46875\n",
      "Epoch [1/5], Step [700/1065], Loss: 206719.8125\n",
      "Epoch [1/5], Step [800/1065], Loss: 131030.328125\n",
      "Epoch [1/5], Step [900/1065], Loss: 132138.90625\n",
      "Epoch [1/5], Step [1000/1065], Loss: 98110.609375\n",
      "Average loss for epoch 1: 249747.85905039613\n",
      "Epoch [2/5], Step [100/1065], Loss: 67302.03125\n",
      "Epoch [2/5], Step [200/1065], Loss: 43398.9609375\n",
      "Epoch [2/5], Step [300/1065], Loss: 38375.859375\n",
      "Epoch [2/5], Step [400/1065], Loss: 71543.96875\n",
      "Epoch [2/5], Step [500/1065], Loss: 22559.0078125\n",
      "Epoch [2/5], Step [600/1065], Loss: 37993.5859375\n",
      "Epoch [2/5], Step [700/1065], Loss: 6713.921875\n",
      "Epoch [2/5], Step [800/1065], Loss: 24576.615234375\n",
      "Epoch [2/5], Step [900/1065], Loss: 8626.7998046875\n",
      "Epoch [2/5], Step [1000/1065], Loss: 12492.85546875\n",
      "Average loss for epoch 2: 31086.28200407073\n",
      "Epoch [3/5], Step [100/1065], Loss: 9479.78125\n",
      "Epoch [3/5], Step [200/1065], Loss: 2649.455322265625\n",
      "Epoch [3/5], Step [300/1065], Loss: 9205.89453125\n",
      "Epoch [3/5], Step [400/1065], Loss: 5401.81298828125\n",
      "Epoch [3/5], Step [500/1065], Loss: 10800.572265625\n",
      "Epoch [3/5], Step [600/1065], Loss: 13469.4970703125\n",
      "Epoch [3/5], Step [700/1065], Loss: 7555.283203125\n",
      "Epoch [3/5], Step [800/1065], Loss: 15879.0166015625\n",
      "Epoch [3/5], Step [900/1065], Loss: 3782.72216796875\n",
      "Epoch [3/5], Step [1000/1065], Loss: 2869.420654296875\n",
      "Average loss for epoch 3: 8397.361551662678\n",
      "Epoch [4/5], Step [100/1065], Loss: 4869.8603515625\n",
      "Epoch [4/5], Step [200/1065], Loss: 4156.205078125\n",
      "Epoch [4/5], Step [300/1065], Loss: 2273.92236328125\n",
      "Epoch [4/5], Step [400/1065], Loss: 4412.75634765625\n",
      "Epoch [4/5], Step [500/1065], Loss: 2065.32861328125\n",
      "Epoch [4/5], Step [600/1065], Loss: 19621.494140625\n",
      "Epoch [4/5], Step [700/1065], Loss: 18082.900390625\n",
      "Epoch [4/5], Step [800/1065], Loss: 17006.37109375\n",
      "Epoch [4/5], Step [900/1065], Loss: 22391.97265625\n",
      "Epoch [4/5], Step [1000/1065], Loss: 2758.8486328125\n",
      "Average loss for epoch 4: 9637.259978531672\n",
      "Epoch [5/5], Step [100/1065], Loss: 9714.6083984375\n",
      "Epoch [5/5], Step [200/1065], Loss: 5392.30029296875\n",
      "Epoch [5/5], Step [300/1065], Loss: 1794.1971435546875\n",
      "Epoch [5/5], Step [400/1065], Loss: 3201.72021484375\n",
      "Epoch [5/5], Step [500/1065], Loss: 785.73681640625\n",
      "Epoch [5/5], Step [600/1065], Loss: 2556.40087890625\n",
      "Epoch [5/5], Step [700/1065], Loss: 2738.99169921875\n",
      "Epoch [5/5], Step [800/1065], Loss: 1565.2091064453125\n",
      "Epoch [5/5], Step [900/1065], Loss: 2646.130615234375\n",
      "Epoch [5/5], Step [1000/1065], Loss: 1545.9964599609375\n",
      "Average loss for epoch 5: 3526.932361527564\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Prepare dataset\n",
    "class MidiDataset(Dataset):\n",
    "    def __init__(self, notes_df, seq_length):\n",
    "        self.notes = notes_df.values  # Convert DataFrame to numpy array\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.notes) - self.seq_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sequence = torch.from_numpy(self.notes[index:index+self.seq_length]).float()\n",
    "        label = torch.from_numpy(self.notes[index+self.seq_length]).float()\n",
    "        return sequence, label\n",
    "\n",
    "# Hyperparameters\n",
    "seq_length = 25\n",
    "batch_size = 64\n",
    "num_epochs = 5\n",
    "\n",
    "# Create DataLoader\n",
    "dataset = MidiDataset(all_notes, seq_length)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Define model\n",
    "class MidiModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MidiModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=5, hidden_size=256, num_layers=2, batch_first=True)\n",
    "        self.fc_pitch = nn.Linear(256, 128)\n",
    "        self.fc_step = nn.Linear(256, 1)\n",
    "        self.fc_duration = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]  # Get last output only\n",
    "        pitch = self.fc_pitch(x)\n",
    "        step = torch.relu(self.fc_step(x))  # To ensure non-negative values\n",
    "        duration = torch.relu(self.fc_duration(x))  # To ensure non-negative values\n",
    "        return {'pitch': pitch, 'step': step, 'duration': duration}\n",
    "\n",
    "model = MidiModel().cuda()\n",
    "\n",
    "# Define custom loss\n",
    "class PositiveMSELoss(nn.MSELoss):\n",
    "    def __init__(self):\n",
    "        super(PositiveMSELoss, self).__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return super().forward(input, target) + 10 * torch.clamp(-input, min=0).mean()\n",
    "\n",
    "losses = {\n",
    "    'pitch': nn.CrossEntropyLoss(),\n",
    "    'step': PositiveMSELoss(),\n",
    "    'duration': PositiveMSELoss(),\n",
    "}\n",
    "loss_weights = {'pitch': 0.05, 'step': 1.0, 'duration': 1.0}\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.005)\n",
    "# Training loop\n",
    "loss_values = []\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for i, (sequence, label) in enumerate(dataloader):\n",
    "        sequence, label = sequence.float().cuda(), label.float().cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(sequence)\n",
    "\n",
    "        # Extract labels for each output type\n",
    "        pitch_label = label[:, 0].long()\n",
    "        step_label = label[:, 1]\n",
    "        duration_label = label[:, 2]\n",
    "\n",
    "        loss = (\n",
    "            loss_weights['pitch'] * losses['pitch'](output['pitch'], pitch_label) +\n",
    "            loss_weights['step'] * losses['step'](output['step'].squeeze(), step_label) +\n",
    "            loss_weights['duration'] * losses['duration'](output['duration'].squeeze(), duration_label)\n",
    "        )\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], Loss: {loss.item()}\")\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)  # if you want average loss per epoch\n",
    "    loss_values.append(avg_loss)\n",
    "    print(f\"Average loss for epoch {epoch+1}: {avg_loss}\")\n",
    "\n",
    "    \n",
    "torch.save(model.state_dict(), \"model.pt\")\n",
    "\n",
    "plt.plot(loss_values)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b14c94b3-3e9a-44dc-9241-15895259da16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MidiModel(\n",
       "  (lstm): LSTM(5, 256, num_layers=2, batch_first=True)\n",
       "  (fc_pitch): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc_step): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (fc_duration): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MidiModel().cuda() \n",
    "model.load_state_dict(torch.load(\"model.pt\"))  # If \"midi_model.pt\" is in the same directory, no need to change this.\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2378591e-7219-4ac6-becb-1df0c1fc23f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_notes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m prev_start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_predictions):\n\u001b[1;32m---> 37\u001b[0m     pitch, step, duration \u001b[38;5;241m=\u001b[39m predict_next_note(\u001b[43minput_notes\u001b[49m, model, temperature)\n\u001b[0;32m     38\u001b[0m     start \u001b[38;5;241m=\u001b[39m prev_start \u001b[38;5;241m+\u001b[39m step\n\u001b[0;32m     39\u001b[0m     end \u001b[38;5;241m=\u001b[39m start \u001b[38;5;241m+\u001b[39m duration\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_notes' is not defined"
     ]
    }
   ],
   "source": [
    "def predict_next_note(notes: np.ndarray, model: MidiModel, temperature: float = 1.0) -> Tuple[int, float, float]:\n",
    "    \"\"\"Generates a note IDs using a trained sequence model.\"\"\"\n",
    "    assert temperature > 0\n",
    "\n",
    "    # Add missing dimensions\n",
    "    notes = np.concatenate((notes, np.zeros((len(notes), 2))), axis=1)\n",
    "\n",
    "    # Add batch dimension\n",
    "    inputs = torch.from_numpy(notes[np.newaxis, ...]).float().cuda()\n",
    "\n",
    "    # Get model predictions\n",
    "    predictions = model(inputs)\n",
    "    pitch_logits = predictions['pitch'].cpu().detach().numpy()\n",
    "    step = predictions['step'].cpu().detach().numpy()\n",
    "    duration = predictions['duration'].cpu().detach().numpy()\n",
    "\n",
    "    pitch_logits /= temperature\n",
    "\n",
    "    # Sample from the softmax distribution (PyTorch's categorical() expects logits, not probabilities)\n",
    "    pitch = torch.distributions.categorical.Categorical(logits=torch.tensor(pitch_logits)).sample().item()\n",
    "    duration = duration[0][0]  # Remove unnecessary dimensions\n",
    "    step = step[0][0]  # Remove unnecessary dimensions\n",
    "\n",
    "    # `step` and `duration` values should be non-negative\n",
    "    step = max(0, step)\n",
    "    duration = max(0, duration)\n",
    "\n",
    "    return int(pitch), float(step), float(duration)\n",
    "\n",
    "temperature = 2.0\n",
    "num_predictions = 120\n",
    "\n",
    "# assuming you have previously defined the 'input_notes' variable\n",
    "generated_notes = []\n",
    "prev_start = 0\n",
    "for _ in range(num_predictions):\n",
    "    pitch, step, duration = predict_next_note(input_notes, model, temperature)\n",
    "    start = prev_start + step\n",
    "    end = start + duration\n",
    "    input_note = (pitch, step, duration)\n",
    "    generated_notes.append((input_note, start, end))\n",
    "    input_notes = np.delete(input_notes, 0, axis=0)\n",
    "    input_notes = np.append(input_notes, np.expand_dims(input_note, 0), axis=0)\n",
    "    prev_start = start\n",
    "\n",
    "generated_notes_df = pd.DataFrame(generated_notes, columns=('pitch', 'step', 'duration', 'start', 'end'))\n",
    "print(generated_notes_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9f0089",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a vectorized function that converts pitch numbers to note names using pretty_midi.note_number_to_name.\n",
    "# np.vectorize applies a function to all elements in an array or sequence.\n",
    "get_note_names = np.vectorize(pretty_midi.note_number_to_name)\n",
    "\n",
    "# Use the vectorized function to convert all pitch values in the 'pitch' column of the raw_notes DataFrame to note names.\n",
    "# The 'pitch' column contains numerical values representing the pitch of each note in MIDI notation.\n",
    "sample_note_names = get_note_names(raw_notes['pitch'])\n",
    "\n",
    "# Print the first 10 note names in the resulting array.\n",
    "sample_note_names[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3f3bd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This function is used to plot a piano roll of a MIDI track.\n",
    "# Piano rolls are a good way to visualize MIDI data, showing the pitch of each note and its start and end times.\n",
    "def plot_piano_roll(notes: pd.DataFrame, count: Optional[int] = None):\n",
    "  # If 'count' is provided, the function will only plot that many notes, and the title of the plot will reflect that.\n",
    "  # If 'count' is not provided, the function will plot all notes in the track, and the title of the plot will say 'Whole track'.\n",
    "  if count:\n",
    "    title = f'First {count} notes'\n",
    "  else:\n",
    "    title = f'Whole track'\n",
    "    count = len(notes['pitch'])\n",
    "  \n",
    "  # Setting the figure size for the plot.\n",
    "  plt.figure(figsize=(20, 4))\n",
    "  \n",
    "  # The 'plot_pitch' array is used for the y-axis of the plot. It repeats the 'pitch' column of 'notes' twice along a new axis.\n",
    "  plot_pitch = np.stack([notes['pitch'], notes['pitch']], axis=0)\n",
    "  \n",
    "  # The 'plot_start_stop' array is used for the x-axis of the plot. It contains the 'start' and 'end' columns of 'notes'.\n",
    "  plot_start_stop = np.stack([notes['start'], notes['end']], axis=0)\n",
    "  \n",
    "  # The 'plot' function is used to create the plot. It draws a blue dot for each note, and connects consecutive notes with blue lines.\n",
    "  plt.plot(\n",
    "      plot_start_stop[:, :count], plot_pitch[:, :count], color=\"b\", marker=\".\")\n",
    "  \n",
    "  # Labeling the x-axis as 'Time [s]' and the y-axis as 'Pitch'.\n",
    "  plt.xlabel('Time [s]')\n",
    "  plt.ylabel('Pitch')\n",
    "  \n",
    "  # Setting the title for the plot.\n",
    "  _ = plt.title(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f5a81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run plot_piano_roll with the first 100 notes\n",
    "plot_piano_roll(raw_notes, count=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501361a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run plot_piano_roll with the entire track\n",
    "plot_piano_roll(raw_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a418aa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function plots the distributions of 'pitch', 'step', and 'duration' fields in a pandas DataFrame of notes from a MIDI file.\n",
    "# By default, it drops the top 2.5 percentile of 'step' and 'duration' values when plotting their histograms to focus on the most common values.\n",
    "def plot_distributions(notes: pd.DataFrame, drop_percentile=2.5):\n",
    "  # Setting the figure size for the plots.\n",
    "  plt.figure(figsize=[15, 5])\n",
    "  \n",
    "  # Subplot for the 'pitch' distribution\n",
    "  plt.subplot(1, 3, 1)  # This creates a subplot grid of 1 row and 3 columns, and selects the first plot for drawing.\n",
    "  sns.histplot(notes, x=\"pitch\", bins=20)  # This creates a histogram of 'pitch' values using Seaborn's histplot function.\n",
    "\n",
    "  # Subplot for the 'step' distribution\n",
    "  plt.subplot(1, 3, 2)  # Selects the second plot for drawing.\n",
    "  max_step = np.percentile(notes['step'], 100 - drop_percentile)  # This calculates the (100 - drop_percentile) percentile of 'step' values.\n",
    "  sns.histplot(notes, x=\"step\", bins=np.linspace(0, max_step, 21))  # This creates a histogram of 'step' values, with bins evenly spaced between 0 and max_step.\n",
    "\n",
    "  # Subplot for the 'duration' distribution\n",
    "  plt.subplot(1, 3, 3)  # Selects the third plot for drawing.\n",
    "  max_duration = np.percentile(notes['duration'], 100 - drop_percentile)  # This calculates the (100 - drop_percentile) percentile of 'duration' values.\n",
    "  sns.histplot(notes, x=\"duration\", bins=np.linspace(0, max_duration, 21))  # This creates a histogram of 'duration' values, with bins evenly spaced between 0 and max_duration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46bd97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distributions(raw_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bbee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a\n",
    "# This function converts a pandas DataFrame of notes back into a MIDI file using the pretty_midi library.\n",
    "# The 'notes' DataFrame should have 'pitch', 'step', and 'duration' columns.\n",
    "# 'pitch' is the pitch of the note, 'step' is the time interval since the start of the previous note, and 'duration' is the duration of the note.\n",
    "# 'out_file' is the path to the output MIDI file.\n",
    "# 'instrument_name' is the name of the instrument to be used in the MIDI file. This should be a string that matches one of the instrument names in the General MIDI standard.\n",
    "# 'velocity' is the loudness of the notes. It defaults to 100, and can range from 0 (silent) to 127 (maximum loudness).\n",
    "def notes_to_midi(\n",
    "  notes: pd.DataFrame,\n",
    "  out_file: str, \n",
    "  instrument_name: str,\n",
    "  velocity: int = 100,  # note loudness\n",
    ") -> pretty_midi.PrettyMIDI:\n",
    "\n",
    "  # Initialize a PrettyMIDI object.\n",
    "  pm = pretty_midi.PrettyMIDI()\n",
    "  \n",
    "  # Create a PrettyMIDI instrument object with the specified name.\n",
    "  instrument = pretty_midi.Instrument(\n",
    "      program=pretty_midi.instrument_name_to_program(\n",
    "          instrument_name))\n",
    "\n",
    "  # Initialize the start time of the first note.\n",
    "  prev_start = 0\n",
    "  \n",
    "  # Iterate over the rows of the notes DataFrame, each representing a note.\n",
    "  for i, note in notes.iterrows():\n",
    "    # Calculate the start and end times of the note in seconds.\n",
    "    start = float(prev_start + note['step'])\n",
    "    end = float(start + note['duration'])\n",
    "    \n",
    "    # Create a PrettyMIDI Note object with the calculated start and end times, the specified velocity, and the pitch from the DataFrame.\n",
    "    note = pretty_midi.Note(\n",
    "        velocity=velocity,\n",
    "        pitch=int(note['pitch']),\n",
    "        start=start,\n",
    "        end=end,\n",
    "    )\n",
    "    \n",
    "    # Append the note to the instrument's notes list.\n",
    "    instrument.notes.append(note)\n",
    "    \n",
    "    # Update the start time for the next note.\n",
    "    prev_start = start\n",
    "\n",
    "  # Append the instrument to the PrettyMIDI object's instruments list.\n",
    "  pm.instruments.append(instrument)\n",
    "  \n",
    "  # Write the PrettyMIDI object to a MIDI file.\n",
    "  pm.write(out_file)\n",
    "  \n",
    "  # Return the PrettyMIDI object.\n",
    "  return pm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cff387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this section of the code, the 'notes_to_midi' function is used to convert the DataFrame 'raw_notes' back into a MIDI file.\n",
    "# The output MIDI file will be written to 'example.midi', and the instrument used will be the one specified by 'instrument_name'.\n",
    "# The 'notes_to_midi' function returns a PrettyMIDI object which is stored in 'example_pm' for further manipulation or analysis.\n",
    "\n",
    "# Specify the filename for the MIDI file to be created.\n",
    "example_file = 'example.midi'\n",
    "\n",
    "# Call the 'notes_to_midi' function with the DataFrame of notes, the output file name, and the instrument name.\n",
    "# The function will convert the DataFrame back into a MIDI file and write it to the specified location.\n",
    "# The resulting PrettyMIDI object is stored in 'example_pm'.\n",
    "example_pm = notes_to_midi(\n",
    "    raw_notes, out_file=example_file, instrument_name=instrument_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4a031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the order of the columns in the DataFrame.\n",
    "key_order = ['pitch', 'step', 'duration']\n",
    "\n",
    "# Stack the columns of the DataFrame into a numpy array, with one column per axis.\n",
    "train_notes = np.stack([all_notes[key] for key in key_order], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1ff175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that train_notes is a numpy array.\n",
    "train_notes = np.array(train_notes)\n",
    "\n",
    "# Convert the numpy array to a PyTorch tensor.\n",
    "train_notes_torch = torch.Tensor(train_notes)\n",
    "\n",
    "# Create a PyTorch Dataset from the tensor.\n",
    "notes_ds = TensorDataset(train_notes_torch)\n",
    "\n",
    "# Retrieve the first element in the dataset.\n",
    "first_element = notes_ds[0]\n",
    "\n",
    "# Print the shape and data type of the first element.\n",
    "print(\"Shape:\", first_element[0].shape)\n",
    "print(\"dtype:\", first_element[0].dtype)\n",
    "\n",
    "# Print the first element of the dataset.\n",
    "print(first_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec32de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(\n",
    "    dataset: torch.Tensor, \n",
    "    seq_length: int,\n",
    "    vocab_size = 128,\n",
    "    batch_size = 32,\n",
    ") -> DataLoader:\n",
    "    \"\"\"Returns PyTorch DataLoader of sequence and label examples.\"\"\"\n",
    "\n",
    "    def scale_pitch(x):\n",
    "        x = x.float()\n",
    "        x[:, 0] /= vocab_size\n",
    "        return x\n",
    "    \n",
    "    seq_length += 1\n",
    "    sequences = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(0, len(dataset) - seq_length, seq_length):\n",
    "        sequence = dataset[i : i + seq_length]\n",
    "        # print (i)\n",
    "        # print (seq_length)\n",
    "        # print(sequence)\n",
    "        sequences.append(scale_pitch(sequence[0]))\n",
    "        # print(sequence)\n",
    "        labels.append(sequence[-1])\n",
    "            \n",
    "    sequences = torch.stack(sequences)\n",
    "    # for i in range(len(sequences)):\n",
    "    #     print(len(sequences[i]))\n",
    "    # print (sequences[0])\n",
    "    labels = torch.stack(labels)\n",
    "    \n",
    "    data = TensorDataset(sequences, labels)\n",
    "    data_loader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return data_loader\n",
    "    \n",
    "\n",
    "    def split_labels(sequences):\n",
    "        inputs = sequences[:-1]\n",
    "        labels_dense = sequences[-1]\n",
    "        labels = {key:labels_dense[i] for i,key in enumerate(key_order)}\n",
    "\n",
    "        return scale_pitch(inputs), labels\n",
    "\n",
    "    split_data = [split_labels(sequence) for sequence in sequences]\n",
    "    return DataLoader(split_data, batch_size=32, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d485823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_sequences(dataset, seq_length):\n",
    "#     sequences = []\n",
    "#     labels = []\n",
    "\n",
    "#     # Extend the sequence length by one for the label\n",
    "#     seq_length += 1\n",
    "\n",
    "#     # Generate sequences and corresponding labels\n",
    "#     for i in range(len(dataset) - seq_length):\n",
    "#         seq = dataset[i:i+seq_length]\n",
    "#         sequences.append(seq[:-1]) # the sequence\n",
    "#         labels.append(seq[-1])     # the label is the last element of seq\n",
    "\n",
    "#     # Convert lists to tensors\n",
    "#     sequences = torch.stack(sequences)\n",
    "#     labels = torch.stack(labels)\n",
    "\n",
    "#     # !! Having issues Scale the pitch\n",
    "#     # scale = torch.Tensor([vocab_size, 1.0, 1.0]).view(1, 3)  # Convert list to Tensor\n",
    "#     # sequences[:, :, 0] = sequences[:, :, 0] / scale[0]\n",
    "\n",
    "#     return sequences, labels\n",
    "\n",
    "# # Convert the tensorflow dataset to numpy arrays\n",
    "\n",
    "# # The values in notes_ds are tuples, so we have to do x[0] to get the tensor with pitch, step, and duration, and then with that tensor\n",
    "# # We have to take the tensor[0] to get pitch, tensor[1] to get step, tensor[2] to get duration\n",
    "\n",
    "# second = notes_ds[2]\n",
    "# print(second[0].shape)\n",
    "# print(second[0].dtype)\n",
    "\n",
    "\n",
    "# notes_data = np.concatenate([x[0].numpy() for x in notes_ds])\n",
    "\n",
    "# # Then convert the numpy arrays to PyTorch tensors\n",
    "# notes_ds = torch.from_numpy(notes_data)\n",
    "\n",
    "# # Create sequences\n",
    "# seq_length = 25\n",
    "# sequences, labels = create_sequences(notes_ds, seq_length)\n",
    "\n",
    "# # One-hot encoding for pitch values of sequences and labels.\n",
    "# sequences_onehot = F.one_hot(sequences[:, :, 0].to(torch.int64), num_classes=128)\n",
    "# labels_onehot = F.one_hot(labels[:, 0].to(torch.int64), num_classes=128)\n",
    "\n",
    "# # Replace the original pitch values in sequences and labels with the one-hot encoded versions.\n",
    "# sequences = torch.cat((sequences_onehot, sequences[:, :, 1:]), dim=2)\n",
    "# labels['pitch'] = labels_onehot\n",
    "\n",
    "\n",
    "# # To inspect the shape of sequences and labels:\n",
    "# for sequences, labels in seq_ds:\n",
    "#     print(\"Sequences shape:\", sequences.shape)\n",
    "#     print(\"Labels shape:\", labels.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0db9274",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_length = 25\n",
    "vocab_size = 128\n",
    "seq_ds = create_sequences(notes_ds, seq_length, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae531a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seq_ds)\n",
    "print(len(seq_ds))\n",
    "\n",
    "tempseq_ds = DataLoader(list(seq_ds), batch_size=32)\n",
    "\n",
    "first_batch_sequences, first_batch_labels = next(iter(tempseq_ds))\n",
    "print('First batch sequences shape:', first_batch_sequences.shape)\n",
    "print('First batch sequences elements (first 10):', first_batch_sequences[0, :5])\n",
    "print('First batch target:', first_batch_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa9aff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = n_notes-seq_length # Set the buffer size\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "\n",
    "train_ds = DataLoader(seq_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "print(len(seq_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dfdfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_with_positive_pressure(y_true: torch.Tensor, y_pred: torch.Tensor):\n",
    "    mse = (y_true - y_pred) ** 2\n",
    "    positive_pressure = 10 * torch.clamp(-y_pred, min=0.0)\n",
    "    return torch.mean(mse + positive_pressure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7b2bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=3, hidden_size=128, batch_first=True)\n",
    "        self.pitch = nn.Linear(128, 128)\n",
    "        self.step = nn.Linear(128, 1)\n",
    "        self.duration = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x, _ = self.lstm(inputs)\n",
    "        x = x[:, -1, :]  # get last output of each sequence\n",
    "        pitch = F.log_softmax(self.pitch(x), dim=1)\n",
    "        step = self.step(x)\n",
    "        duration = self.duration(x)\n",
    "        outputs = {'pitch': pitch, 'step': step, 'duration': duration}\n",
    "        return outputs\n",
    "    \n",
    "def evaluate(model, data_loader, criterions):\n",
    "    model.eval() \n",
    "    total_loss = 0\n",
    "    with torch.no_grad(): \n",
    "        for inputs, targets in data_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss_pitch = criterions['pitch'](outputs['pitch'], targets['pitch'])\n",
    "            loss_step = criterions['step'](outputs['step'], targets['step'])\n",
    "            loss_duration = criterions['duration'](outputs['duration'], targets['duration'])\n",
    "            loss = loss_pitch + loss_step + loss_duration\n",
    "            print(loss_pitch.shape)\n",
    "            print(loss_step.shape)\n",
    "            print(loss_duration.shape)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# class MyDataset(Dataset):\n",
    "#     def __init__(self, inputs, targets):\n",
    "#         self.inputs = inputs\n",
    "#         self.targets = targets\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.inputs)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.inputs[idx], {k: v[idx] for k, v in self.targets.items()}\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        target_dict = {'pitch': self.targets[idx, 0],\n",
    "                       'step': self.targets[idx, 1],\n",
    "                       'duration': self.targets[idx, 2]}\n",
    "        return self.inputs[idx], target_dict\n",
    "\n",
    "\n",
    "# Instantiate model and print the structure\n",
    "model = MyModel()\n",
    "print(model)\n",
    "\n",
    "# Define optimizer\n",
    "learning_rate = 0.005\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define loss functions\n",
    "criterion_pitch = nn.NLLLoss()  # Negative Log Likelihood Loss\n",
    "criterion_step = mse_with_positive_pressure\n",
    "criterion_duration = mse_with_positive_pressure\n",
    "criterions = {'pitch': criterion_pitch, 'step': criterion_step, 'duration': criterion_duration}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642f9d95-205e-4d96-ba7f-121b97376e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 26 \n",
    "\n",
    "inputs = []\n",
    "targets = []\n",
    "\n",
    "#train_notes has a tensor size of 3\n",
    "for i in range(0, len(train_notes) - sequence_length):\n",
    "    inputs.append(train_notes[i:i + sequence_length])\n",
    "    targets.append(train_notes[i + sequence_length])\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "inputs = np.array(inputs, dtype = np.float32)\n",
    "targets = torch.Tensor(targets).long()\n",
    "\n",
    "# Now you have your inputs and targets, which you can use in the model\n",
    "print(inputs.shape)\n",
    "print(targets.shape)\n",
    "\n",
    "# # Create a DataLoader (replace with your actual data)\n",
    "dataset = MyDataset(inputs, targets)\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# # Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in data_loader:\n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        # Compute loss\n",
    "        loss_pitch = criterion_pitch(outputs['pitch'], targets['pitch'])\n",
    "        loss_step = criterion_step(outputs['step'], targets['step'])\n",
    "        loss_duration = criterion_duration(outputs['duration'], targets['duration'])\n",
    "        # Combine the losses\n",
    "        loss = loss_pitch + loss_step + loss_duration\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, running_loss/len(data_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ccc8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(inputs, targets)\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "print(len(train_ds))\n",
    "# losses = evaluate(model, train_ds, criterions)\n",
    "# print(\"Losses: \", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c4e31-cce0-418b-b333-e20f638ffbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert sequences and labels to DataLoader\n",
    "seq_ds = DataLoader(list(zip(sequences, labels)), batch_size=32)\n",
    "\n",
    "# To inspect the shape of sequences and labels:\n",
    "for sequences, labels in seq_ds:\n",
    "    print(\"Sequences shape:\", sequences.shape)\n",
    "    print(\"Labels shape:\", labels.shape)\n",
    "    break\n",
    "\n",
    "# Now, you should split your `sequences` and `labels` into a training and validation set:\n",
    "train_inputs, val_inputs, train_labels, val_labels = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Then, you can create your datasets\n",
    "train_dataset = MyDataset(train_inputs, train_labels)\n",
    "val_dataset = MyDataset(val_inputs, val_labels)\n",
    "\n",
    "# And your DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2a6a41-7e34-4048-9ea6-4fdbc24cc8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split each target\n",
    "train_targets_pitch, val_targets_pitch = train_test_split(targets['pitch'], test_size=0.2, random_state=42)\n",
    "train_targets_step, val_targets_step = train_test_split(targets['step'], test_size=0.2, random_state=42)\n",
    "train_targets_duration, val_targets_duration = train_test_split(targets['duration'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Combine targets into dictionary\n",
    "train_targets = {'pitch': train_targets_pitch, 'step': train_targets_step, 'duration': train_targets_duration}\n",
    "val_targets = {'pitch': val_targets_pitch, 'step': val_targets_step, 'duration': val_targets_duration}\n",
    "\n",
    "# Create your datasets\n",
    "train_dataset = MyDataset(train_inputs, train_targets)\n",
    "val_dataset = MyDataset(val_inputs, val_targets)\n",
    "\n",
    "# Create your DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e379c54-e84d-460c-b4a2-2359726eeb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(targets['pitch'].shape)\n",
    "print(targets['step'].shape)\n",
    "print(targets['duration'].shape)\n",
    "\n",
    "print(train_targets_pitch.shape, val_targets_pitch.shape)\n",
    "print(train_targets_step.shape, val_targets_step.shape)\n",
    "print(train_targets_duration.shape, val_targets_duration.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0ba8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callbacks:\n",
    "    def __init__(self, patience=7, verbose=False, checkpoint_path='./training_checkpoints/ckpt_'):\n",
    "        self.early_stopping = EarlyStopping(patience, verbose)\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "\n",
    "    def check(self, epoch, loss, model):\n",
    "        self.early_stopping(loss, model)\n",
    "        self.save_checkpoint(epoch, model)\n",
    "        return self.early_stopping.early_stop\n",
    "\n",
    "    def save_checkpoint(self, epoch, model):\n",
    "        '''Saves model when a new epoch starts'''\n",
    "        torch.save(model.state_dict(), self.checkpoint_path + str(epoch+1))\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.best_score:.6f} --> {score:.6f}).  Saving model ...')\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "\n",
    "val_dataset = MyDataset(val_inputs, val_targets)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Usage in your training loop:\n",
    "callbacks = Callbacks(patience=5, verbose=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training steps\n",
    "    # ...\n",
    "\n",
    "    # Validation steps\n",
    "    val_loss = evaluate(model, val_loader, criterions)\n",
    "    print(\"Validation Loss:\", val_loss)\n",
    "\n",
    "    # Callbacks check\n",
    "    if callbacks.check(epoch, val_loss, model):\n",
    "        print(\"Early stopping\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42a31bf-99f2-4bf3-ae8e-e11d571d300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", torch.cuda.device_count())\n",
    "print(\"Built with CUDA: \", torch.cuda.is_available())\n",
    "print(\"PyTorch version: \", torch.__version__)\n",
    "import sys\n",
    "print(\"Python version: \", sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4fd28f-811c-4dba-bd07-11f598545855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Number of epochs\n",
    "epochs = 50\n",
    "\n",
    "# Initialize the Callbacks\n",
    "callbacks = Callbacks(patience=5, verbose=True)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    # Training steps\n",
    "    for inputs, targets in train_ds:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss_pitch = criterion_pitch(outputs['pitch'], targets['pitch'])\n",
    "        loss_step = criterion_step(outputs['step'], targets['step'])\n",
    "        loss_duration = criterion_duration(outputs['duration'], targets['duration'])\n",
    "        loss = loss_pitch + loss_step + loss_duration\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Validation steps\n",
    "    val_loss = evaluate(model, val_loader)\n",
    "    print(\"Epoch [{}/{}], Loss: {:.4f}, Validation Loss: {:.4f}\".format(epoch+1, epochs, running_loss/len(train_ds), val_loss))\n",
    "    \n",
    "    # Check the callbacks\n",
    "    callbacks.step(epoch, model, val_loss)\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Training Time: %s seconds\" % (end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8e819e-701c-4474-b99c-cf2b17f3d6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history['loss'], label='total loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be417d1-7bb1-48ea-a497-6568919b7d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_note(\n",
    "    notes: np.ndarray, \n",
    "    keras_model: tf.keras.Model, \n",
    "    temperature: float = 1.0) -> int:\n",
    "  \"\"\"Generates a note IDs using a trained sequence model.\"\"\"\n",
    "\n",
    "  assert temperature > 0\n",
    "\n",
    "  # Add batch dimension\n",
    "  inputs = tf.expand_dims(notes, 0)\n",
    "\n",
    "  predictions = model.predict(inputs)\n",
    "  pitch_logits = predictions['pitch']\n",
    "  step = predictions['step']\n",
    "  duration = predictions['duration']\n",
    "\n",
    "  pitch_logits /= temperature\n",
    "  pitch = tf.random.categorical(pitch_logits, num_samples=1)\n",
    "  pitch = tf.squeeze(pitch, axis=-1)\n",
    "  duration = tf.squeeze(duration, axis=-1)\n",
    "  step = tf.squeeze(step, axis=-1)\n",
    "\n",
    "  # `step` and `duration` values should be non-negative\n",
    "  step = tf.maximum(0, step)\n",
    "  duration = tf.maximum(0, duration)\n",
    "\n",
    "  return int(pitch), float(step), float(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f0e47d-2e80-475c-ad2c-c5799a40a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 2.0\n",
    "num_predictions = 120\n",
    "\n",
    "sample_notes = np.stack([raw_notes[key] for key in key_order], axis=1)\n",
    "\n",
    "# The initial sequence of notes; pitch is normalized similar to training\n",
    "# sequences\n",
    "input_notes = (\n",
    "    sample_notes[:seq_length] / np.array([vocab_size, 1, 1]))\n",
    "\n",
    "generated_notes = []\n",
    "prev_start = 0\n",
    "for _ in range(num_predictions):\n",
    "  pitch, step, duration = predict_next_note(input_notes, model, temperature)\n",
    "  start = prev_start + step\n",
    "  end = start + duration\n",
    "  input_note = (pitch, step, duration)\n",
    "  generated_notes.append((*input_note, start, end))\n",
    "  input_notes = np.delete(input_notes, 0, axis=0)\n",
    "  input_notes = np.append(input_notes, np.expand_dims(input_note, 0), axis=0)\n",
    "  prev_start = start\n",
    "\n",
    "generated_notes = pd.DataFrame(\n",
    "    generated_notes, columns=(*key_order, 'start', 'end'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d623a8-5467-4da3-b28d-33fed7057478",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_notes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b92c60-45b1-4f92-93d6-ebaa46480046",
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_output = pretty_midi.PrettyMIDI()\n",
    "\n",
    "# Create an instrument instance for a piano\n",
    "piano_program = pretty_midi.instrument_name_to_program('Acoustic Grand Piano')\n",
    "piano = pretty_midi.Instrument(program=piano_program)\n",
    "\n",
    "# Iterate through the generated notes\n",
    "for index, row in generated_notes.iterrows():\n",
    "    pitch, step, duration, start, end = row\n",
    "\n",
    "    # Create a Note instance for the current note\n",
    "    note = pretty_midi.Note(velocity=100, pitch=int(pitch), start=start, end=end)\n",
    "\n",
    "    # Add the note to the piano instrument\n",
    "    piano.notes.append(note)\n",
    "\n",
    "# Add the piano instrument to the PrettyMIDI object\n",
    "midi_output.instruments.append(piano)\n",
    "\n",
    "# Save the MIDI file\n",
    "# Save the MIDI file\n",
    "with open('output.mid', 'wb') as midi_file:\n",
    "    midi_file.write(midi_output.synthesize())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
